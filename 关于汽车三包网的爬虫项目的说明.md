# 关于汽车三包网的爬虫项目的说明

爬取的链接：

https://www.qcsanbao.cn/webqcba/DVMProducerServlet?method=getAllList

### 项目的启动方式：python  start.py

**在配置文件中，test: 默认是True测试环境，正式环境 切换成false**

##### 						   thread_num: 开启的线程数量



### 去重

主要使用的是redis的**set**

redis的set集合，当元素存在集合中的时候，存在的元素不能再次存储在set的集合中。

在这里我们用两个集合**all_url_list** 和**url_list**, all_url_list主要用于判断去重，url_list主要用于提取链接，进行下载和解析。

当要爬取的数据不在all_url_list中的时候，我们同时将他加入all_url_list和url_list的集合中，当我们得到的数据在all_url_list中的时候，说明我们已经爬取完成了或者等待爬取这个链接，这样就不用了加入到我们数据库中，实现去重的功能。



### 断点续爬

实际上还是读取redis数据库中,我们可以知道存储在数据库中的数据是还没有爬取的数据，直接将redis中的数据直接读取，进行下载，解析，即可完成数据的断点续爬。



#### 代码的结构说明

![捕获](C:\Users\a21036\Desktop\捕获.PNG)

config.py  主要是项目的配置文件，包括数据库的链接配置、文件夹的路径设置等

downloads.py  主要是和下载相关的类的封装，包括下载网页，pdf文件等

parse.py   主要是和解析相关的类的封装，解析html文本获取想要的数据和url链接，部分放入redis进行存储

**start.py**   项目的启动文件，直接运行即可

tools.py  工具文件，主要是项目用的函数的封装。



#### 数据的存储

**1、pdf的存储地址**：

以pdf的http请求路径境进行存储地址的构造

sanbaobeian.dpac.org.com.cn\uploads\AttachementData\xxxxxxx.pdf

**2、html的存储地址**：

两级固定的目录：www.qcsanbao.cn\webqcba

在下面需要存储的html文件包括

列表页的存储：**page0001.html**  page0002.html ......page1296.html（要求页面之间可以完成上下页，首末页跳转）

品牌页的存储：**品牌名称.html** 

code页的存储：一辆车对应一个code,格式：**品牌名称_code.html**

三包页面目录：**品牌名称_code**

三包详情信息页的存储：**品牌名称_code_detail.html**

三包pdf下载页的存储：**品牌名称_code_detaill_附件信息20201111001.html**













